{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1pNrK4geAtd4TWH9rtRA2i8cehqTN_lvc",
      "authorship_tag": "ABX9TyNdSyNxBIUVSI2YK3HkOmbd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/OVP2023/CV/blob/main/tracking_%D0%BB%D0%B8%D1%86%D0%B0_%D1%81_%D0%B2%D0%B5%D0%B1_%D0%BA%D0%B0%D0%BC%D0%B5%D1%80%D1%8B.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7CVxBeFr8GR8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31cbab0a-95eb-4640-8f6c-8823225db7b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.11.0\n"
          ]
        }
      ],
      "source": [
        "#Пример работы трекера лица по видео с веб-камеры\n",
        "import cv2\n",
        "\n",
        "print(cv2.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Загружаем предобученную модель детектора лица\n",
        "face_cascade = cv2.CascadeClassifier('/content/drive/MyDrive/Datasets/CV/tracking/haarcascade_frontalface_default.xml')"
      ],
      "metadata": {
        "id": "hZBlt-kNULTS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install yt-dlp"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cucz7s_j0KMP",
        "outputId": "0a8ee823-f20f-4c8f-ffff-fd89f0d561ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: yt-dlp in /usr/local/lib/python3.11/dist-packages (2025.2.19)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from yt_dlp import YoutubeDL"
      ],
      "metadata": {
        "id": "lDasG452kX0i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Загрузка трансляции\n",
        "url = \"https://rutube.ru/video/6bed3b96454ff7d87583f3969ebb5f0f/\"\n",
        "\n",
        "ydl_opts = {\n",
        "    'format': 'best', #выбор лучшего доступного формата\n",
        "    'quiet':True,\n",
        "}\n",
        "with YoutubeDL(ydl_opts) as ydl:\n",
        "    info=ydl.extract_info(url,download=False)\n",
        "    video_url=info['url']\n"
      ],
      "metadata": {
        "id": "4EuXs9gkmL_2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Загрузка видео файла трансляции с rutube.ru\n",
        "\n",
        "url = \"https://rutube.ru/video/6bed3b96454ff7d87583f3969ebb5f0f/\"\n",
        "\n",
        "ydl_opts = {\n",
        "    'format': 'best', #выбор лучшего доступного формата\n",
        "    'outtmpl':'video.%(ext)s',\n",
        "}\n",
        "\n",
        "with YoutubeDL(ydl_opts) as ydl:\n",
        "    ydl.download([url])\n",
        "video_url='video.mp4'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        },
        "id": "Mb1gjnQI1mfN",
        "outputId": "e6da2f01-0ed0-4dd7-d23e-7556adab2a74"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'yt_dlp'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-db66c6823c7e>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0myt_dlp\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mYoutubeDL\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"https://rutube.ru/video/6bed3b96454ff7d87583f3969ebb5f0f/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m ydl_opts = {\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'yt_dlp'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab.patches import cv2_imshow  #используем в колабе cv2_imshow вместо cv2.imshow\n",
        "\n",
        "camera = cv2.VideoCapture(video_url)\n",
        "#Число, которое мы передаем, означает источник. 0 – первая веб-камера в вашей системе, 1 – вторая и т.д.\n",
        "#Если вы хотите загрузить уже существующий видеофайл вместо захвата прямой трансляции, просто на место номера вставьте путь к нему.\n",
        "if not camera.isOpened():\n",
        "    print('ошибка не удалось открыть видео поток')\n",
        "else:\n",
        "    #ret, frame = camera.read()\n",
        "    #cv2_imshow('video feed', camera.frame)\n",
        "    a=1\n",
        "camera  #свойства   https://www.geeksforgeeks.org/how-to-get-properties-of-python-cv2-videocapture-object/\n",
        "print(\"CV_CAP_PROP_FRAME_WIDTH: '{}'\".format(camera.get(cv2.CAP_PROP_FRAME_WIDTH))) #ширина кадра в видео потоке в пикселях\n",
        "print(\"CV_CAP_PROP_FRAME_HEIGHT : '{}'\".format(camera.get(cv2.CAP_PROP_FRAME_HEIGHT)))\n",
        "print(\"CAP_PROP_FPS : '{}'\".format(camera.get(cv2.CAP_PROP_FPS))) #количество кадров в сек\n",
        "print(\"CAP_PROP_POS_MSEC : '{}'\".format(camera.get(cv2.CAP_PROP_POS_MSEC)))\n",
        "print(\"CAP_PROP_FRAME_COUNT  : '{}'\".format(camera.get(cv2.CAP_PROP_FRAME_COUNT)))\n",
        "print(\"CAP_PROP_BRIGHTNESS : '{}'\".format(camera.get(cv2.CAP_PROP_BRIGHTNESS)))\n",
        "print(\"CAP_PROP_CONTRAST : '{}'\".format(camera.get(cv2.CAP_PROP_CONTRAST)))\n",
        "print(\"CAP_PROP_SATURATION : '{}'\".format(camera.get(cv2.CAP_PROP_SATURATION)))\n",
        "print(\"CAP_PROP_HUE : '{}'\".format(camera.get(cv2.CAP_PROP_HUE)))\n",
        "print(\"CAP_PROP_GAIN  : '{}'\".format(camera.get(cv2.CAP_PROP_GAIN)))\n",
        "print(\"CAP_PROP_CONVERT_RGB : '{}'\".format(camera.get(cv2.CAP_PROP_CONVERT_RGB)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WzBBTzAWWA42",
        "outputId": "ebdc3c30-d1a6-4e95-9a3e-6ffd8435865f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CV_CAP_PROP_FRAME_WIDTH: '1920.0'\n",
            "CV_CAP_PROP_FRAME_HEIGHT : '1080.0'\n",
            "CAP_PROP_FPS : '25.0'\n",
            "CAP_PROP_POS_MSEC : '0.0'\n",
            "CAP_PROP_FRAME_COUNT  : '25504.0'\n",
            "CAP_PROP_BRIGHTNESS : '0.0'\n",
            "CAP_PROP_CONTRAST : '0.0'\n",
            "CAP_PROP_SATURATION : '0.0'\n",
            "CAP_PROP_HUE : '0.0'\n",
            "CAP_PROP_GAIN  : '0.0'\n",
            "CAP_PROP_CONVERT_RGB : '1.0'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "kcf_tracker = None  # объект трекера инициализируется при первой детекции лица\n",
        "\n",
        "#Затем создадим цикл while, чтобы получать из источника кадр за кадром.\n",
        "while(1):\n",
        "    ret, frame = camera.read()\n",
        "    frame = cv2.flip(frame, 1)\n",
        "\n",
        "    print('считывание кадра',ret)   #Функция cap.read() возвращает логическое значение (True/False) и кадр. Если кадр был считан верно, то возвращается True.\n",
        "    if ret==True:\n",
        "        cv2_imshow(frame)\n",
        "\n",
        "\n",
        "    kcf_tracker_box = None  # результат работы трекера\n",
        "\n",
        "    if kcf_tracker is not None:\n",
        "        # обновляем трекер и получаем результат трекинга\n",
        "        ok, box = kcf_tracker.update(frame)\n",
        "        # сохраняем результат трекинга\n",
        "        if ok:\n",
        "            kcf_tracker_box = box\n",
        "\n",
        "    # преобразуем изображение в чернобелый формат\n",
        "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # запускаем детектор лиц\n",
        "    faces = face_cascade.detectMultiScale(gray, 1.3, 3)\n",
        "\n",
        "    # инициализируем трекер первой детекцией\n",
        "    if len(faces) != 0 and kcf_tracker is None:\n",
        "        kcf_tracker = cv2.TrackerKCF_create()\n",
        "        (x, y, w, h) = faces[0]\n",
        "        kcf_tracker.init(frame, (x,y,w,h))\n",
        "\n",
        "    for (x,y,w,h) in faces:\n",
        "        # отрисовываем детекцию лиц\n",
        "        cv2.rectangle(frame,(x,y),(x+w,y+h),(255,0,0), 2)\n",
        "        cv2.putText(frame, 'Detector', (x, y - 10),\n",
        "                    cv2.FONT_HERSHEY_SIMPLEX, 1,\n",
        "                    (255, 0, 0), 2, cv2.LINE_AA)\n",
        "\n",
        "    # отрисовываем результат трекера\n",
        "    if kcf_tracker_box is not None:\n",
        "        (x, y, w, h) = map(int, kcf_tracker_box)\n",
        "        cv2.rectangle(frame, (x,y),(x+w,y+h), (0, 0, 255), 2)\n",
        "        cv2.putText(frame, 'Tracker', (x, y - 10),\n",
        "                    cv2.FONT_HERSHEY_SIMPLEX, 1,\n",
        "                    (0, 0, 255), 2, cv2.LINE_AA)\n",
        "\n",
        "    cv2_imshow(frame)\n",
        "    interrupt=cv2.waitKey(10)\n",
        "\n",
        "    # выход по нажатию на клавишу 'q'\n",
        "    if  interrupt & 0xFF == ord('q'):\n",
        "        break\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "Rnm_DI_wXoAO",
        "outputId": "02ef9825-fbf0-47f1-eedd-e6ca37a9eccd"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"kcf_tracker = None  # объект трекера инициализируется при первой детекции лица\\n\\n#Затем создадим цикл while, чтобы получать из источника кадр за кадром.\\nwhile(1):\\n    ret, frame = camera.read()\\n    frame = cv2.flip(frame, 1)\\n\\n    print('считывание кадра',ret)   #Функция cap.read() возвращает логическое значение (True/False) и кадр. Если кадр был считан верно, то возвращается True.\\n    if ret==True:\\n        cv2_imshow(frame)\\n\\n\\n    kcf_tracker_box = None  # результат работы трекера\\n\\n    if kcf_tracker is not None:\\n        # обновляем трекер и получаем результат трекинга\\n        ok, box = kcf_tracker.update(frame)\\n        # сохраняем результат трекинга\\n        if ok:\\n            kcf_tracker_box = box\\n\\n    # преобразуем изображение в чернобелый формат\\n    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\\n\\n    # запускаем детектор лиц\\n    faces = face_cascade.detectMultiScale(gray, 1.3, 3)\\n\\n    # инициализируем трекер первой детекцией\\n    if len(faces) != 0 and kcf_tracker is None:\\n        kcf_tracker = cv2.TrackerKCF_create()\\n        (x, y, w, h) = faces[0]\\n        kcf_tracker.init(frame, (x,y,w,h))\\n\\n    for (x,y,w,h) in faces:\\n        # отрисовываем детекцию лиц\\n        cv2.rectangle(frame,(x,y),(x+w,y+h),(255,0,0), 2)\\n        cv2.putText(frame, 'Detector', (x, y - 10),\\n                    cv2.FONT_HERSHEY_SIMPLEX, 1,\\n                    (255, 0, 0), 2, cv2.LINE_AA)\\n\\n    # отрисовываем результат трекера\\n    if kcf_tracker_box is not None:\\n        (x, y, w, h) = map(int, kcf_tracker_box)\\n        cv2.rectangle(frame, (x,y),(x+w,y+h), (0, 0, 255), 2)\\n        cv2.putText(frame, 'Tracker', (x, y - 10),\\n                    cv2.FONT_HERSHEY_SIMPLEX, 1,\\n                    (0, 0, 255), 2, cv2.LINE_AA)\\n\\n    cv2_imshow(frame)\\n    interrupt=cv2.waitKey(10)\\n\\n    # выход по нажатию на клавишу 'q'\\n    if  interrupt & 0xFF == ord('q'):\\n        break\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#После того, как мы закончим использовать камеру, ее нужно «освободить». Если мы этого не сделаем, то в следующий раз при попытке ее использовать, вы получите ошибку.\n",
        "camera.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "NWKtYFy-Cm2V"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}